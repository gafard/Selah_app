import 'package:just_audio/just_audio.dart';
import 'package:audio_session/audio_session.dart';
import 'package:hive/hive.dart';
import 'semantic_passage_boundary_service.dart';

/// üß† Contexte audio intelligent
class AudioContext {
  final String? reference;
  final String? theme;
  final Map<String, dynamic>? metadata;
  
  AudioContext({
    this.reference,
    this.theme,
    this.metadata,
  });
}

/// üß† Contexte s√©mantique pour audio
class SemanticContext {
  final String unitName;
  final String priority;
  final String theme;
  final String? liturgicalContext;
  final List<String> emotionalTones;
  final String? annotation;
  
  SemanticContext({
    required this.unitName,
    required this.priority,
    required this.theme,
    this.liturgicalContext,
    this.emotionalTones = const [],
    this.annotation,
  });
}

/// üß† PROPH√àTE - Lecteur audio avec intelligence s√©mantique
/// 
/// Niveau : Proph√®te (Intelligent) - Service intelligent pour l'audio adaptatif
/// 
/// Priorit√©s d'interaction :
/// üî• Priorit√© 1: semantic_passage_boundary_service.dart (FALCON X)
/// üî• Priorit√© 2: thompson_plan_service.dart (th√®mes)
/// üî• Priorit√© 3: bible_context_service.dart (contexte)
/// üéØ Thompson: Enrichit l'exp√©rience audio avec th√®mes spirituels
class AudioPlayerService {
  final _player = AudioPlayer();
  Box? _audioPrefsBox;
  
  /// üß† Initialise le lecteur audio intelligent avec contexte
  Future<void> init({required Uri url, AudioContext? context}) async {
    // Initialiser la box Hive pour les pr√©f√©rences audio
    _audioPrefsBox = await Hive.openBox('audio_prefs');
    
    final session = await AudioSession.instance;
    await session.configure(const AudioSessionConfiguration.music());
    
    // üß† INTELLIGENCE CONTEXTUELLE - Configurer selon le contexte
    if (context != null) {
      await _configureIntelligentAudio(context);
    }
    
    await _player.setAudioSource(AudioSource.uri(url));
    
    print('üèéÔ∏è Proph√®te Intelligent: Lecteur audio initialis√© avec contexte');
  }

  /// üß† Configure l'audio selon le contexte intelligent
  Future<void> _configureIntelligentAudio(AudioContext context) async {
    try {
      // üî• PRIORIT√â 1: R√©cup√©rer le contexte s√©mantique FALCON X
      final semanticContext = await _getSemanticContext(context);
      
      // üî• PRIORIT√â 2: R√©cup√©rer le th√®me Thompson
      final thompsonTheme = await _getThompsonTheme(context);
      
      // üî• PRIORIT√â 3: R√©cup√©rer les pr√©f√©rences utilisateur
      final userPrefs = await _getUserAudioPreferences();
      
      // üß† MACHINE LEARNING: Adapter la vitesse selon le contexte
      final optimalSpeed = _calculateOptimalSpeed(semanticContext, thompsonTheme, userPrefs);
      await _player.setSpeed(optimalSpeed);
      
      // üß† MACHINE LEARNING: Adapter le volume selon le contexte
      final optimalVolume = _calculateOptimalVolume(semanticContext, thompsonTheme, userPrefs);
      await _player.setVolume(optimalVolume);
      
      // Sauvegarder les pr√©f√©rences apprises
      await _saveLearnedPreferences(context, optimalSpeed, optimalVolume);
      
    } catch (e) {
      print('‚ö†Ô∏è Erreur configuration audio intelligente: $e');
    }
  }

  /// üî• PRIORIT√â 1: R√©cup√®re le contexte s√©mantique FALCON X
  Future<SemanticContext?> _getSemanticContext(AudioContext context) async {
    try {
      if (context.reference != null) {
        // Extraire livre et chapitre de la r√©f√©rence
        final parts = context.reference!.split(' ');
        if (parts.length >= 2) {
          final book = parts[0];
          final chapter = int.tryParse(parts[1]);
          if (chapter != null) {
            final unit = SemanticPassageBoundaryService.findUnitContaining(book, chapter);
            if (unit != null) {
              return SemanticContext(
                unitName: unit.name,
                priority: unit.priority.name,
                theme: unit.theme ?? '',
                liturgicalContext: unit.liturgicalContext ?? '',
                emotionalTones: unit.emotionalTones ?? [],
                annotation: unit.annotation,
              );
            }
          }
        }
      }
      return null;
    } catch (e) {
      return null;
    }
  }

  /// üî• PRIORIT√â 2: R√©cup√®re le th√®me Thompson
  Future<String?> _getThompsonTheme(AudioContext context) async {
    try {
      if (context.reference != null) {
        // TODO: Int√©grer avec thompson_plan_service pour r√©cup√©rer le th√®me
        // Mapping basique pour l'instant
        if (context.reference!.contains('Psaumes')) {
          return 'Vie de pri√®re ‚Äî Souffle spirituel';
        } else if (context.reference!.contains('Jean')) {
          return 'Exigence spirituelle ‚Äî Transformation profonde';
        }
      }
      return null;
    } catch (e) {
      return null;
    }
  }

  /// üî• PRIORIT√â 3: R√©cup√®re les pr√©f√©rences utilisateur
  Future<Map<String, dynamic>?> _getUserAudioPreferences() async {
    try {
      // TODO: Int√©grer avec user_prefs_hive pour r√©cup√©rer les pr√©f√©rences audio
      return {
        'preferredSpeed': 1.0,
        'preferredVolume': 0.8,
        'thompsonEnabled': true,
      };
    } catch (e) {
      return null;
    }
  }

  /// üß† Calcule la vitesse optimale selon le contexte
  double _calculateOptimalSpeed(SemanticContext? semantic, String? thompson, Map<String, dynamic>? prefs) {
    double baseSpeed = prefs?['preferredSpeed'] ?? 1.0;
    
    // Adapter selon le contexte s√©mantique
    if (semantic != null) {
      if (semantic.priority == 'critical') {
        baseSpeed *= 0.8; // Ralentir pour les passages critiques
      } else if (semantic.priority == 'low') {
        baseSpeed *= 1.2; // Acc√©l√©rer pour les passages moins critiques
      }
    }
    
    // Adapter selon le th√®me Thompson
    if (thompson != null) {
      if (thompson.contains('pri√®re')) {
        baseSpeed *= 0.9; // Ralentir pour la pri√®re
      } else if (thompson.contains('sagesse')) {
        baseSpeed *= 1.1; // Acc√©l√©rer pour la sagesse
      }
    }
    
    return baseSpeed.clamp(0.5, 2.0);
  }

  /// üß† Calcule le volume optimal selon le contexte
  double _calculateOptimalVolume(SemanticContext? semantic, String? thompson, Map<String, dynamic>? prefs) {
    double baseVolume = prefs?['preferredVolume'] ?? 0.8;
    
    // Adapter selon le contexte s√©mantique
    if (semantic != null) {
      if (semantic.emotionalTones.contains('peaceful')) {
        baseVolume *= 0.9; // Volume plus doux pour la paix
      } else if (semantic.emotionalTones.contains('powerful')) {
        baseVolume *= 1.1; // Volume plus fort pour la puissance
      }
    }
    
    return baseVolume.clamp(0.1, 1.0);
  }

  /// üß† Sauvegarde les pr√©f√©rences apprises
  Future<void> _saveLearnedPreferences(AudioContext context, double speed, double volume) async {
    try {
      final key = '${context.reference ?? 'default'}_${DateTime.now().day}';
      await _audioPrefsBox?.put(key, {
        'speed': speed,
        'volume': volume,
        'timestamp': DateTime.now().toIso8601String(),
      });
    } catch (e) {
      print('‚ö†Ô∏è Erreur sauvegarde pr√©f√©rences audio: $e');
    }
  }
  
  Stream<Duration> get position$ => _player.positionStream;
  Stream<Duration?> get duration$ => _player.durationStream;
  Stream<PlayerState> get state$ => _player.playerStateStream;
  
  Future<void> play() => _player.play();
  Future<void> pause() => _player.pause();
  Future<void> seek(Duration d) => _player.seek(d);
  Future<void> dispose() => _player.dispose();
  
  // Get current position synchronously
  Duration get position => _player.position;
  Duration? get duration => _player.duration;
  PlayerState get state => _player.playerState;
  
  // Check if currently playing
  bool get isPlaying => _player.playing;

  /// üß† M√©thode intelligente pour jouer avec contexte
  Future<void> playWithContext(AudioContext context) async {
    await _configureIntelligentAudio(context);
    await play();
  }

  /// üß† M√©thode intelligente pour ajuster la vitesse selon le contexte
  Future<void> adjustSpeedForContext(AudioContext context) async {
    final semanticContext = await _getSemanticContext(context);
    final thompsonTheme = await _getThompsonTheme(context);
    final userPrefs = await _getUserAudioPreferences();
    
    final optimalSpeed = _calculateOptimalSpeed(semanticContext, thompsonTheme, userPrefs);
    await _player.setSpeed(optimalSpeed);
    
    print('üèéÔ∏è Proph√®te Intelligent: Vitesse ajust√©e √† $optimalSpeed selon le contexte');
  }

  /// üß† M√©thode intelligente pour ajuster le volume selon le contexte
  Future<void> adjustVolumeForContext(AudioContext context) async {
    final semanticContext = await _getSemanticContext(context);
    final thompsonTheme = await _getThompsonTheme(context);
    final userPrefs = await _getUserAudioPreferences();
    
    final optimalVolume = _calculateOptimalVolume(semanticContext, thompsonTheme, userPrefs);
    await _player.setVolume(optimalVolume);
    
    print('üèéÔ∏è Proph√®te Intelligent: Volume ajust√© √† $optimalVolume selon le contexte');
  }

  /// üß† R√©cup√®re les pr√©f√©rences apprises pour un contexte
  Future<Map<String, dynamic>?> getLearnedPreferences(AudioContext context) async {
    try {
      final key = '${context.reference ?? 'default'}_${DateTime.now().day}';
      return _audioPrefsBox?.get(key);
    } catch (e) {
      return null;
    }
  }
}
